{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPE0EmAOMQ0OQnDI3kLdSo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install nibabel #to read .nii files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAEmYTmwHDG9","executionInfo":{"status":"ok","timestamp":1708325509118,"user_tz":-345,"elapsed":6669,"user":{"displayName":"Nhyuumila Kasaa","userId":"04260173526866381772"}},"outputId":"310c48ce-ef34-441c-cc0f-0d2b0be0aef9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.25.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import nibabel as nib\n","import glob #a function that's used to search for files that match a specific file pattern or name.\n","from tensorflow.keras.utils import to_categorical #since this is multiclass classification\n","import matplotlib.pyplot as plt\n","from tifffile import imsave # to save as tiff file\n","\n","from sklearn.preprocessing import MinMaxScaler # to scale all values between 0-1\n","scaler = MinMaxScaler()"],"metadata":{"id":"btskcESwIqQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# looking at training dataset path\n","\n","# Coding on sample test images\n","TRAIN_DATASET_PATH = 'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n","#VALIDATION_DATASET_PATH = 'BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n","\n","test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_flair.nii').get_fdata()\n","print(test_image_flair.max()) # prints max float point. After scaling point is either 0 or 1.\n","#Scalers are applied to 1D so let us reshape to 3D and then reshape back to original shape.\n","test_image_flair=scaler.fit_transform(test_image_flair.reshape(-1, test_image_flair.shape[-1])).reshape(test_image_flair.shape)\n","# scaling\n","\n","\n","test_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1.nii').get_fdata()\n","test_image_t1=scaler.fit_transform(test_image_t1.reshape(-1, test_image_t1.shape[-1])).reshape(test_image_t1.shape)\n","\n","test_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1ce.nii').get_fdata()\n","test_image_t1ce=scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n","\n","test_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t2.nii').get_fdata()\n","test_image_t2=scaler.fit_transform(test_image_t2.reshape(-1, test_image_t2.shape[-1])).reshape(test_image_t2.shape)\n","\n","# for mask; no scaling; 0124 are labels,float point\n","test_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_seg.nii').get_fdata()\n","test_mask=test_mask.astype(np.uint8)\n","\n","print(np.unique(test_mask))  #0, 1, 2, 4 (Need to reencode to 0, 1, 2, 3)\n","test_mask[test_mask==4] = 3  #Reassign mask values 4 to 3 i.e 4=3\n","print(np.unique(test_mask))\n","\n","import random\n","n_slice=random.randint(0, test_mask.shape[2]) #randomly selecting a slics from image\n","\n","plt.figure(figsize=(12, 8))\n","\n","# printing flair image\n","plt.subplot(231)\n","plt.imshow(test_image_flair[:,:,n_slice], cmap='gray')\n","plt.title('Image flair')\n","plt.subplot(232)\n","plt.imshow(test_image_t1[:,:,n_slice], cmap='gray')\n","plt.title('Image t1')\n","plt.subplot(233)\n","plt.imshow(test_image_t1ce[:,:,n_slice], cmap='gray')\n","plt.title('Image t1ce')\n","plt.subplot(234)\n","plt.imshow(test_image_t2[:,:,n_slice], cmap='gray')\n","plt.title('Image t2')\n","plt.subplot(235)\n","plt.imshow(test_mask[:,:,n_slice])\n","plt.title('Mask')\n","plt.show()\n","\n","#we get segmented masks sort of images\n"],"metadata":{"id":"oArCRYnFJezE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PART 2: Explore the process of combining images to channels and\n","\n","#Combine t1ce, t2, and flair into single multichannel image(single volume)\n","\n","#converting in single numpy array\n","combined_x = np.stack([test_image_flair, test_image_t1ce, test_image_t2], axis=3)\n","# 3d multi volumes sort of\n","\n","#Crop\n","#to a size to be divisible by 64 so we can later extract 64x64x64 patches.\n","#cropping x, y, and z\n","# cropping to remove black portion\n","# done for test datas\n","\n","combined_x=combined_x[56:184, 56:184, 13:141] #Crop to 128x128x128x4\n","\n","test_mask = test_mask[56:184, 56:184, 13:141]\n","\n","n_slice=random.randint(0, test_mask.shape[2])\n","plt.figure(figsize=(12, 8))\n","\n","plt.subplot(221)\n","plt.imshow(combined_x[:,:,n_slice, 0], cmap='gray')\n","plt.title('Image flair')\n","plt.subplot(222)\n","plt.imshow(combined_x[:,:,n_slice, 1], cmap='gray')\n","plt.title('Image t1ce')\n","plt.subplot(223)\n","plt.imshow(combined_x[:,:,n_slice, 2], cmap='gray')\n","plt.title('Image t2')\n","plt.subplot(224)\n","plt.imshow(test_mask[:,:,n_slice])\n","plt.title('Mask')\n","plt.show()\n","\n","\n","imsave('BraTS2020_TrainingData/combined255.tif', combined_x)\n","np.save('BraTS2020_TrainingData/combined255.npy', combined_x) #data processed saved as numpy array\n","#Verify image is being read properly\n","#my_img=imread('BraTS2020_TrainingData/combined255.tif')\n","\n","my_img=np.load('BraTS2020_TrainingData/combined255.npy') # files saved as numpy array\n","\n","test_mask = to_categorical(test_mask, num_classes=4)\n","#converted to categorical\n","#End of understanding the dataset. Now get it organized.\n"],"metadata":{"id":"jgogBK3rmaIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Now let us apply the same as above to all the images...\n","#Merge channels, crop, patchify, save\n","#GET DATA READY =  GENERATORS OR OTHERWISE\n","\n","#Keras datagenerator does ntot support 3d\n","\n","# Defining img list; mask to categorical\n","\n","#t1_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1.nii'))\n","t2_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t2.nii'))\n","t1ce_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1ce.nii'))\n","flair_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*flair.nii'))\n","mask_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*seg.nii'))\n","\n","#Each volume generates 18 64x64x64x4 sub-volumes.\n","#Total 369 volumes = 6642 sub volumes\n","\n","for img in range(len(t2_list)):   #Using t1_list as all lists are of same size\n","    print(\"Now preparing image and masks number: \", img)\n","\n","     #load image and transform\n","    temp_image_t2=nib.load(t2_list[img]).get_fdata()\n","    temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n","\n","    temp_image_t1ce=nib.load(t1ce_list[img]).get_fdata()\n","    temp_image_t1ce=scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n","\n","    temp_image_flair=nib.load(flair_list[img]).get_fdata()\n","    temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n","\n","    temp_mask=nib.load(mask_list[img]).get_fdata()\n","    temp_mask=temp_mask.astype(np.uint8)\n","    temp_mask[temp_mask==4] = 3  #Reassign mask values 4 to 3\n","    #print(np.unique(temp_mask))\n","\n","    #stack along axis 3\n","    temp_combined_images = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2], axis=3)\n","\n","    #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches.\n","    #cropping x, y, and z\n","    temp_combined_images=temp_combined_images[56:184, 56:184, 13:141]\n","    temp_mask = temp_mask[56:184, 56:184, 13:141]\n","\n","    val, counts = np.unique(temp_mask, return_counts=True)\n","    # returns how many 0123\n","\n","    #if volume has <1% of masks, not used\n","\n","    if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n","        print(\"Save Me\")\n","        temp_mask= to_categorical(temp_mask, num_classes=4) #convert to categorical\n","        np.save('BraTS2020_TrainingData/input_data_3channels/images/image_'+str(img)+'.npy', temp_combined_images)\n","        np.save('BraTS2020_TrainingData/input_data_3channels/masks/mask_'+str(img)+'.npy', temp_mask)\n","\n","    else:\n","        print(\"I am useless\")\n","\n","\n","################################################################\n","#Repeat the same from above for validation data folder OR\n","#Split training data into train and validation\n","\n","\"\"\"\n","Code for splitting folder into train, test, and val.\n","Once the new folders are created rename them and arrange in the format below to be used\n","for semantic segmentation using data generators.\n","\n","pip install split-folders\n","\"\"\"\n","import splitfolders  # or import split_folders\n","\n","input_folder = 'BraTS2020_TrainingData/input_data_3channels/'\n","output_folder = 'BraTS2020_TrainingData/input_data_128/'\n","# Split with a ratio.\n","# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n","splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None) # default values\n","########################################"],"metadata":{"id":"TqMMLXM7sZT1"},"execution_count":null,"outputs":[]}]}